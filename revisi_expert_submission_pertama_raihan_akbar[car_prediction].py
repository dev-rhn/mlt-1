# -*- coding: utf-8 -*-
"""Revisi_Expert_Submission_Pertama_Raihan Akbar[Car Prediction].ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ETMLpc6MDkq_JcbAlY0qDbq7Of4aAyjd

# **Import Library**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns
import os

"""# **Data Loading**

Pada tahapan Data Loading, saya melakukan setup untuk melakukan download dataset melalui kaggle dan menentukan lokasi penyimpanan dataset di google drive
"""

# Import module yang disediakan google colab untuk kebutuhan upload file
from google.colab import files
files.upload()

# Buat direktori .kaggle jika belum ada
kaggle_dir = "/root/.kaggle"
if not os.path.exists(kaggle_dir):
    os.makedirs(kaggle_dir)

# Pindahkan file kaggle.json
!mv /content/kaggle-expert.json $kaggle_dir/kaggle.json

# Berikan izin yang sesuai pada file kaggle.json
!chmod 600 $kaggle_dir/kaggle.json

# Lokasi folder di Google Drive tempat menyimpan dataset
DATASET_PATH="/content/drive/MyDrive/Dataset/ford-car-price-prediction"

# Buat folder di Google Drive jika belum ada
!mkdir -p $DATASET_PATH

# Download dataset dari Kaggle
!kaggle datasets download -d adhurimquku/ford-car-price-prediction -p $DATASET_PATH

# Ekstrak dataset langsung ke Google Drive
!unzip $DATASET_PATH/ford-car-price-prediction.zip -d $DATASET_PATH

# Hapus file ZIP setelah ekstraksi
!rm $DATASET_PATH/ford-car-price-prediction.zip

"""Setelah berhasil di download, saya mendeklarasi kan variabel lokasi dataset. Dengan menggunakan fungsi **pd.read_csv()** saya mencoba untuk membaca data dari file dengan format Comma Separated Values (CSV) dan mengubahnya menjadi sebuah objek DataFrame. Informasi yang didapatkan berupa jumlah **data 17.966 row dan 9 column**"""

dataset = "/content/drive/MyDrive/Dataset/ford-car-price-prediction/ford.csv"
df = pd.read_csv(dataset)

df

"""# **Data Understanding**

## **Exploratory Data Analysis - Deskripsi Variabel**

Langkah selajutnya melakukan EDA dengan memahami masing-masing deskripsi variabel. Dengan menggunakan **df.info()** saya ingin mengetahui masing-masing data pada setiap column dan tipe datanya.

1. **model** -> Kolom ini berisi berbagai model atau jenis mobil yang diproduksi oleh merek Ford.

2. **year** -> Kolom ini menunjukkan tahun kapan mobil tersebut diproduksi atau dibuat. Informasi ini penting untuk mengetahui usia mobil.

3. **price** -> Kolom ini mencantumkan harga jual mobil dalam mata uang Dollar Amerika Serikat.

4. **transmission** -> Kolom ini mengindikasikan jenis sistem transmisi yang digunakan oleh mobil. Terdapat tiga pilihan, Automatic, Manual, Semi-Auto

5. **mileage** -> Jumlah Mil yang Telah Ditempuh: Kolom ini mencatat total jarak yang telah ditempuh oleh mobil, diukur dalam satuan mil. Ini sering menjadi indikator seberapa sering dan jauh mobil telah digunakan.

6. **fuel_Type** -> Kolom ini menjelaskan jenis bahan bakar yang digunakan oleh mobil, Petrol, Diesel, Hybrid, Electric, Other

7. **tax** -> Kolom ini menunjukkan besaran pajak tahunan yang harus dibayarkan untuk mobil tersebut.

8. **mpg** -> Kolom ini mengukur efisiensi bahan bakar mobil, yaitu seberapa jauh mobil dapat menempuh perjalanan (dalam mil) dengan satu galon bahan bakar. Angka yang lebih tinggi menunjukkan mobil yang lebih hemat bahan bakar.

9. **engineSize** -> Kolom ini menunjukkan kapasitas atau ukuran mesin mobil, biasanya diukur dalam liter (L).

Semua kolom memiliki **17.966 nilai non-null**, menandakan tidak ada data yang hilang.
"""

df.info()

"""**df.describe()** memberikan gambaran sekilas tentang distribusi dan karakteristik data numerik dalam DataFrame. Perbedaan signifikan antara nilai minimum/maksimum dan kuartil (25%, 50%, 75%) dapat mengindikasikan adanya outlier dalam data."""

df.describe()

"""## **Exploratory Data Analysis - Univariate Analysis**

Tahap selanjutnya dalam proses EDA yaitu melakukan Univariate Analysis yaitu teknik analisis data yang fokus pada pemeriksaan dan deskripsi satu variabel tunggal pada suatu waktu. Pada tahapan ini akan dibagi menjadi dua fitur yaitu numerical features dan categorical features.
"""

num_features = ['year', 'price', 'mileage', 'tax', 'mpg', 'engineSize']
cat_features = ['model', 'transmission', 'fuelType']

"""### **Categorical Features**

Berdasarkan output yang dihasilkan didapati bahwa model **Fiesta** menjadi model yang paling banyak terjual dengan total 6.557 dan disusul model **Focus** dengan 4.588 dan model **Kuga** dengan 2.225. Selain itu juga banyak model lain yang terjual namun tidak sebanyak 3 model mobil sebelumnya.
"""

feature = cat_features[0]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
model = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(model)
count.plot(kind='bar', title=feature);

"""Berdasarkan output yang dihasilkan transmission yang paling banyak adalah Manual dengan 86% dari total data yang ada. Hal ini menunjukkan model mobil dengan transmission Manual merupakan model yang paling laku dipasaran"""

feature = cat_features[1]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
transmission = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(transmission)
count.plot(kind='bar', title=feature);

"""Berdasarkan output dibawah ini dari sisi tipe bahan bakar yang banyak digunakan, Petrol mendominasi dengan 12.179 dan disusul oleh Diesel dengan 5.762. Kedua tipe ini lebih dominan dibandingkan dengan tipe lain seperti Hybrid dan Electric. Hal ini menunjukkan bahwa pada masa itu kendaraan listrik belum begitu populer di kalangan masyarakat."""

feature = cat_features[2]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
event_type = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(event_type)
count.plot(kind='bar', title=feature);

"""### **Numerical Features**

Berikut ini penjelasan masing-masing histogram:
1. Sebagian besar mobil dalam dataset ini diproduksi antara tahun 2016 dan 2019, dengan tahun 2017 menjadi tahun produksi terbanyak. Jumlah mobil dari tahun-tahun yang lebih tua atau lebih baru cenderung lebih sedikit dalam dataset ini.
2. Sebagian besar mobil dalam dataset ini memiliki harga di kisaran yang lebih rendah, dengan sejumlah kecil mobil yang memiliki harga premium atau mewah.
3. Sebagian besar mobil dalam dataset ini memiliki jarak tempuh yang relatif rendah, menunjukkan bahwa banyak mobil mungkin masih relatif baru atau tidak terlalu sering digunakan.
4. Sistem atau aturan perpajakan untuk mobil-mobil ini kemungkinan memiliki beberapa tingkatan atau kelompok tarif pajak yang berbeda, menyebabkan konsentrasi jumlah mobil pada nilai-nilai pajak tertentu.
5. Penggunaan bahan bakar mobil dalam dataset ini terkumpul di beberapa rentang tertentu, menunjukkan adanya berbagai jenis transmission yang menghasilkan tingkat efisiensi yang berbeda. Puncak di sekitar 60-65 mpg menunjukkan rentang efisiensi yang paling umum.
6. Ukuran mesin mobil dalam dataset ini terkonsentrasi pada beberapa nilai tertentu, terutama 1.0, diikuti oleh 1.6 dan 2.0. Ukuran mesin lainnya kurang umum dalam dataset ini.
"""

df.hist(bins=50, figsize=(20,15))
plt.show()

"""# **Exploratory Data Analysis - Multivariate Analysis**

## **Categorical Features**

Gambar ini menampilkan tiga buah bar plot yang memvisualisasikan rata-rata harga (price) mobil Ford berdasarkan tiga variabel kategorikal yang berbeda, model, transmission, dan fuelType. Berikut ini detail penjelasannya:

---

**1. Rata-rata harga berdasarkan model mobil**
*   Beberapa model seperti Edge, Tourneo Custom, dan Galaxy cenderung memiliki rata-rata harga yang jauh lebih tinggi dibandingkan model lain seperti KA, Fiesta, dan Focus.

*   Model seperti Puma, Kuga, Mondeo, S-MAX, B-MAX, Tourneo Connect, dan Grand C-MAX berada di kisaran harga menengah.

---

**2. Rata-rata Harga Berdasarkan Jenis Transmisi**
*   Mobil dengan transmisi Automatic cenderung memiliki rata-rata harga yang lebih tinggi dibandingkan mobil dengan transmisi Manual.
*   Mobil dengan transmisi Semi-Auto memiliki rata-rata harga yang paling tinggi di antara ketiganya.

---

**3. Rata-rata Harga Berdasarkan Jenis Bahan Bakar**
*   Mobil dengan bahan bakar Hybrid memiliki rata-rata harga yang paling tinggi secara signifikan dibandingkan jenis bahan bakar lainnya dalam dataset ini.
*   Mobil dengan bahan bakar Electric juga memiliki rata-rata harga yang cukup tinggi, meskipun sedikit di bawah Hybrid.
*   Mobil dengan bahan bakar Petrol dan Diesel memiliki rata-rata harga yang relatif mirip dan lebih rendah dibandingkan Hybrid dan Electric.

---
"""

cat_features = df.select_dtypes(include='object').columns.to_list()

for col in cat_features:
  sns.catplot(x=col, y="price", kind="bar", dodge=False, height = 4, aspect = 3,  data=df, palette="Set3")
  plt.title("Rata-rata 'price' Relatif terhadap - {}".format(col))

"""## **Numerical Features**

Gambar ini menampilkan sebuah pair plot yang dibuat menggunakan library seaborn. Pair plot sangat berguna untuk memvisualisasikan hubungan antara pasangan variabel numerik dalam sebuah dataset. Dalam kasus ini,variabel - variabel numerik yang dianalisis adalah 'year', 'price', 'mileage', dan 'tax', mpg, dan engineSize.
"""

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(df, diag_kind = 'kde')

"""Gambar dibawah ini menampilkan sebuah Correlation Matrix (Matriks Korelasi) yang divisualisasikan menggunakan heatmap. Matriks ini menunjukkan koefisien korelasi antara pasangan fitur-fitur numerik dalam dataset mobil. Beberapa fitur menunjukkan korelasi yang cukup kuat (misalnya, tahun dengan harga dan jarak tempuh), sementara yang lain memiliki korelasi yang lemah."""

plt.figure(figsize=(10, 8))
correlation_matrix = df[num_features].corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

df

"""# **Data Preparation**

## **Penanganan Outlier**

Output dibawah ini merupakan sebuah boxplot yang menampilkan distribusi harga mobil (price) dari dataset. Dapat dilihat bahwa sebagian besar harga berada dalam rentang 0-25000, namun ada sejumlah mobil dengan harga yang jauh lebih tinggi yang berperan sebagai *outlier* dan menyebabkan distribusi harga menjadi miring ke kanan.
"""

sns.boxplot(x=df['price'])

"""Output dibawah ini merupakan sebuah boxplot yang menampilkan distribusi jarak tempuh mobil (milage) dari dataset. Dapat dilihat bahwa sebagian besar distribusi jarak tempuh berada dalam rentang 0-60000, namun ada sejumlah mobil dengan jarak tempuh yang jauh lebih tinggi yang berperan sebagai *outlier* dan menyebabkan distribusi jarak tempuh mobil menjadi miring ke kanan."""

sns.boxplot(x=df['mileage'])

"""Output dibawah ini merupakan sebuah boxplot yang menampilkan distribusi pajak mobil (tax) dari dataset. Dapat dilihat bahwa sebagian besar distribusi pajak berada dalam rentang 0-120, namun ada sejumlah mobil dengan pajak yang jauh lebih tinggi yang berperan sebagai *outlier* dan menyebabkan distribusi pajak mobil menjadi miring ke kanan."""

sns.boxplot(x=df['tax'])

"""Output dibawah ini merupakan sebuah boxplot yang menampilkan distribusi penggunaan bahan bakar mobil (mpg) dari dataset. Dapat dilihat bahwa sebagian besar penggunaan bahan bakar berada dalam rentang 25-80, namun ada sejumlah mobil dengan penggunaan yang jauh lebih rendah yang berperan sebagai *outlier* dan menyebabkan distribusi penggunaan bahan bakar mobil menjadi miring ke kiri."""

sns.boxplot(x=df['mpg'])

"""Output dibawah ini merupakan sebuah boxplot yang memberikan visualisasi distribusi ukuran mesin mobil pada dataset. Sebagian besar mobil memiliki ukuran mesin antara 1.0 dan 2.0 liter, dengan distribusi yang cukup merata di rentang tersebut. Namun, terdapat beberapa outlier yang menunjukkan adanya mobil dengan ukuran mesin yang jauh lebih kecil dan jauh lebih besar dibandingkan dengan mayoritas."""

sns.boxplot(x=df['engineSize'])

"""Pada kode dibawah ini saya melakukan identifikasi outlier dengan menggunakan metode IQR (Interquartile Range) pada kolom-kolom numerik dalam DataFrame dan kemudian menghapus seluruh baris yang mengandung outlier pada salah satu kolom numerik tersebut. Setelah menghapus data yang mengandung outlier, data tersisa 16.448 data."""

# Identifikasi kolom-kolom numerik yang ingin dianalisis outliernya
numeric_cols = df.select_dtypes(include=['number']).columns

if not numeric_cols.empty:
    Q1 = df[numeric_cols].quantile(0.25)
    Q3 = df[numeric_cols].quantile(0.75)
    IQR = Q3 - Q1

    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Membuat boolean mask untuk mengidentifikasi baris yang berada dalam batas IQR
    within_bounds = ~((df[numeric_cols] < lower_bound) | (df[numeric_cols] > upper_bound)).any(axis=1)

    # Memfilter DataFrame untuk hanya menyertakan baris yang berada dalam batas IQR
    df = df[within_bounds]
else:
    print("Tidak ada kolom numerik yang ditemukan dalam DataFrame 'df'.")
    # Atau Anda bisa memberikan penanganan kesalahan lain sesuai kebutuhan

# Cek ukuran dataset setelah kita drop outliers
df.shape

"""## **Pengecekan Missing Value**"""

# Cek missing value per kolom
missing_values_count = df.isnull().sum()
print("Jumlah missing value per kolom:\n", missing_values_count)

# Cek total missing value dalam seluruh DataFrame
total_missing = df.isnull().sum().sum()
print("\nTotal missing value dalam DataFrame:", total_missing)

"""## **Encoding Fitur Kategori**

***One-hot encoding*** adalah teknik yang umum digunakan untuk mengubah data kategorikal menjadi format numerik yang dapat dipahami oleh sebagian besar algoritma machine learning. Setiap kategori dalam sebuah fitur kategorikal diubah menjadi kolom biner (0 atau 1). Ini mencegah algoritma mengasumsikan adanya urutan atau jarak antara kategori (seperti yang mungkin terjadi jika kita hanya memberikan label numerik pada kategori).
"""

from sklearn.preprocessing import  OneHotEncoder
df = pd.concat([df, pd.get_dummies(df['model'], prefix='model')],axis=1)
df = pd.concat([df, pd.get_dummies(df['transmission'], prefix='transmission')],axis=1)
df = pd.concat([df, pd.get_dummies(df['fuelType'], prefix='fuelType')],axis=1)
df.drop(['model','transmission','fuelType'], axis=1, inplace=True)
df.head()

"""## **Train-Test-Split**

Kode ini memisahkan dataset menjadi fitur (X) yang berisi semua kolom kecuali 'price', dan target (y) yang hanya berisi kolom 'price'. Selanjutnya, fungsi train_test_split membagi data ini menjadi set pelatihan (80% untuk X_train dan y_train) yang akan digunakan untuk melatih model, dan set pengujian (20% untuk X_test dan y_test) yang akan digunakan untuk mengevaluasi performa model pada data yang belum pernah dilihat, dengan random_state=123 memastikan pembagian data yang konsisten untuk reproduktibilitas.
"""

from sklearn.model_selection import train_test_split

X = df.drop(["price"],axis =1)
y = df["price"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""## **Standarisasi**

Kode ini bertujuan untuk melakukan standardisasi pada fitur-fitur numerik tertentu ('year', 'mileage', 'tax', 'mpg', 'engineSize') dalam set pelatihan (X_train). Standardisasi dilakukan menggunakan StandardScaler dari scikit-learn, yang menghitung mean dan standar deviasi dari setiap fitur numerik dalam X_train, kemudian mentransformasikan nilai-nilai fitur tersebut sehingga memiliki mean mendekati nol dan standar deviasi mendekati satu. Proses ini penting untuk memastikan bahwa fitur-fitur numerik dengan skala yang berbeda tidak memberikan pengaruh yang tidak proporsional pada model machine learning dan dapat membantu algoritma konvergen lebih cepat.
"""

from sklearn.preprocessing import StandardScaler

numerical_features = ['year', 'mileage', 'tax', 'mpg', 'engineSize']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

X_train[numerical_features].describe().round(4)

"""# **Model Development**

Kode ini bertujuan untuk menginisialisasi sebuah DataFrame pandas bernama models yang akan digunakan untuk menyimpan dan membandingkan metrik evaluasi performa dari berbagai model regresi yang berbeda. DataFrame ini memiliki dua baris, 'train_mse' (Mean Squared Error pada set pelatihan) dan 'test_mse' (Mean Squared Error pada set pengujian), serta enam kolom yang masing-masing akan menampung hasil evaluasi untuk model K-Nearest Neighbors (KNN), Random Forest (RF), Gradient Boosting ('Boosting'), Linear Regression (LR), XGBoost (XGB), dan LightGBM (LGBM). Dengan DataFrame ini, hasil evaluasi dari setiap model dapat disimpan dan dibandingkan secara terstruktur.
"""

from sklearn.metrics import mean_squared_error, r2_score

# Siapkan dataframe untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['KNN', 'RF', 'Boosting', 'LR', 'XGB', 'LGBM'])

"""## **KNN**"""

from sklearn.neighbors import KNeighborsRegressor

knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)

models.loc['train_mse','KNN'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""# **Random Forest**"""

# Impor library yang dibutuhkan
from sklearn.ensemble import RandomForestRegressor

# buat model prediksi
RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)

models.loc['train_mse','RF'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""## **AdaBoost**"""

from sklearn.ensemble import AdaBoostRegressor

boosting = AdaBoostRegressor(learning_rate=0.001, random_state=55)
boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""## **Linear Regression**"""

from sklearn.linear_model import LinearRegression

LR = LinearRegression()
LR.fit(X_train, y_train)
models.loc['train_mse', 'LR'] = mean_squared_error(y_pred=LR.predict(X_train), y_true=y_train)

"""## **XGBoost**"""

from xgboost import XGBRegressor

XGB = XGBRegressor()
XGB.fit(X_train, y_train)

models.loc['train_mse','XGB'] = mean_squared_error(y_pred=XGB.predict(X_train), y_true=y_train)

"""## **LightGBM**"""

from lightgbm import LGBMRegressor

LGBM = LGBMRegressor()
LGBM.fit(X_train, y_train)

models.loc['train_mse','LGBM'] = mean_squared_error(y_pred=LGBM.predict(X_train), y_true=y_train)

"""## **Evaluasi Model**

Kode ini bertujuan untuk menerapkan standardisasi yang telah dipelajari dari data pelatihan (X_train) ke fitur-fitur numerik dalam set pengujian (X_test). Dengan menggunakan objek scaler yang sebelumnya telah di-fit pada X_train, kode ini mentransformasikan nilai-nilai fitur numerik di X_test sehingga memiliki skala yang serupa dengan data pelatihan (rata-rata mendekati nol dan varians mendekati satu).
"""

# Lakukan scaling terhadap fitur numerik pada X_test sehingga memiliki rata-rata=0 dan varians=1
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting', 'LR', 'XGB', 'LGBM'])

# Siapkan dataframe untuk nilai R-squared
r_squared = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting', 'LR', 'XGB', 'LGBM'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting, 'LR': LR, 'XGB': XGB, 'LGBM': LGBM}

# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

    # Hitung R-squared
    r_squared.loc[name, 'train'] = r2_score(y_true=y_train, y_pred=model.predict(X_train))
    r_squared.loc[name, 'test'] = r2_score(y_true=y_test, y_pred=model.predict(X_test))

"""Berdasarkan nilai MSE pada data pengujian:

Performa Terbaik (MSE Terendah): XGBoost dan LGBM menunjukkan performa terbaik dalam melakukan generalisasi ke data yang belum pernah dilihat.
Overfitting Signifikan: KNN dan Random Forest mengalami overfitting yang cukup besar, di mana performa pada data pelatihan jauh lebih baik daripada pada data pengujian.
Potensi Underfitting atau Model Sederhana: Boosting dan Linear Regression memiliki nilai MSE yang lebih tinggi secara keseluruhan, yang mungkin mengindikasikan bahwa model tersebut tidak cukup kompleks untuk menangkap pola dalam data dengan baik.
"""

# Panggil mse
mse

"""Berdasarkan nilai R² pada data pengujian:

Performa Terbaik (R² Tertinggi): XGBoost dan LGBM menunjukkan performa terbaik dalam menjelaskan varians harga pada data yang belum pernah dilihat. Random Forest juga sangat baik.
Generalisasi Baik: Sebagian besar model menunjukkan generalisasi yang cukup baik karena nilai R² pada data pengujian tidak jauh berbeda dari nilai pada data pelatihan.
Performa Lebih Rendah: Boosting dan Linear Regression memiliki nilai R² yang lebih rendah dibandingkan model lainnya, menunjukkan bahwa mereka tidak menjelaskan varians dalam harga sebaik model-model tree-based atau berbasis tetangga.

Secara keseluruhan, berdasarkan metrik R², model XGBoost, LightGBM, dan Random Forest tampaknya menjadi pilihan terbaik untuk memprediksi harga mobil dalam dataset ini. Mereka mampu menjelaskan sebagian besar varians dalam harga dan menunjukkan kemampuan generalisasi yang baik.
"""

# Panggil mse
r_squared

"""Kesimpulan:

Model Terbaik (MSE Terendah pada Test Set): Berdasarkan visualisasi ini, LGBM dan XGBoost menunjukkan performa terbaik dalam melakukan generalisasi ke data yang belum pernah dilihat (MSE terendah pada batang oranye).
Overfitting: Random Forest (RF) menunjukkan overfitting yang jelas karena MSE pada data pelatihan sangat rendah, tetapi meningkat tajam pada data pengujian. KNN juga menunjukkan indikasi overfitting.

Performa Kurang Baik: Boosting dan Linear Regression (LR) memiliki performa prediksi yang kurang baik secara keseluruhan (MSE tinggi pada test set).
Untuk tugas regresi ini, LGBM dan XGBoost tampaknya menjadi pilihan model yang lebih baik karena memiliki MSE yang rendah pada data pengujian dan menunjukkan generalisasi yang baik (perbedaan kecil antara train dan test MSE).
"""

fig, ax = plt.subplots()
mse.sort_values(by='train', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)